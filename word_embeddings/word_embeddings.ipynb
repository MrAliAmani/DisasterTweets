{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard"
      ],
      "metadata": {
        "id": "vh7m34vwtJ3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "sOTI1gn7i_q7"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import tensorboard\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "\n",
        "dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,\n",
        "                                  untar=True,cache_dir='.',\n",
        "                                  cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "os.listdir(dataset_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgYc9QtijeY1",
        "outputId": "3b1d1ab7-6672-44af-eaba-b9b57e4bc440"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 7s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README', 'test', 'imdbEr.txt', 'imdb.vocab', 'train']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3102taCUkPL9",
        "outputId": "ee62129d-d48a-44f8-d00b-7635021c911c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['labeledBow.feat',\n",
              " 'urls_unsup.txt',\n",
              " 'pos',\n",
              " 'unsupBow.feat',\n",
              " 'neg',\n",
              " 'unsup',\n",
              " 'urls_neg.txt',\n",
              " 'urls_pos.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "metadata": {
        "id": "-1fpIYI4kv_6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "seed = 123\n",
        "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=batch_size, validation_split=.2,\n",
        "    subset=\"training\", seed=seed\n",
        ")\n",
        "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/test', batch_size=batch_size, validation_split=.2,\n",
        "    subset='validation', seed=seed\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqrXrYDQk8r5",
        "outputId": "147249ba-adfe-4233-9a7d-cb5268576bf6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(5):\n",
        "    print(label_batch[i].numpy(), text_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk21R9ujl8jT",
        "outputId": "e844684d-ccf2-4597-fa28-01f51cbe932e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 b'I believe this is the most powerful film HBO Pictures has made to date. This film should have been released in theaters for the public to view on the big screen. It is available on video so make sure you look for it and check it out. Chris Gerolmo did a great job with the direction and the screenplay. The performances from Stephen Rea, Donald Sutherland and Jeffery DeMunn are flawless. A masterpiece of the genre.'\n",
            "0 b'*** THIS CONTAINS MANY, MANY SPOILERS, NOT THAT IT MATTERS, SINCE EVERYTHING IS SO PATENTLY OBVIOUS ***<br /><br />Oh my God, where do I start? Well, here - this is the first time I have ever come home from a movie and said \"I have to get on IMDb and write a review of this NOW. It is my civic duty.\" Such is the badness of this flick. <br /><br />*begin digression* But let me just state one thing before I start. I\\'m not some Harvard-art-major-film-noir-weenie (in fact, I went to the college at the other end of Mass. Ave in Cambridge, the one where the actual smart people without rich daddies and trust funds go, which should put me squarely in the nerd-who-would-obsessively-love-comic-book-films census group, and still I hated this film...). My viewing preference is for the highbrow cinematic oeuvre that includes the Die Hards, Bond flicks, Clerks, and The Grail. I wish the Titanic had never sunk, not so much for the lives lost, but so we wouldn\\'t have been subjected to that dung-heap of a film. And the single and only reason I will watch a snooty French art film is if there is a young and frequently disrobed Emmanuelle Beart in it. I even gave Maximum Overdrive one of its precious few 10s here on IMDb, for God\\'s sake. So I\\'m as shallow as they come, therefore I\\'m not criticizing this film because I\\'m looking for some standard of cinematic excellence - it\\'s because Elektra stinks like a three-week-old dead goat. *end digression*<br /><br />OK, there\\'s so much badness here that I have to try to categorize it. Here goes:<br /><br />MS. GARNER: One of the compelling reasons a male would want to see this flick is to see lots of hot JGar (I have no idea why my wife wanted to). I think that between this and \"Finding Nemo\", the latter was the sexier film. You know the red outfit she\\'s advertised wearing in every freaking ad you see? You see her in it TWICE - once at the beginning, once at the end. Bummer. In the rest, she basically looks like what Morrissey would look like if he were a female - lots of pouting and black clothes. Which brings me to the incredible range of expression JGar shows in her acting - ranging from \"pouting\" all the way to \"pouting and crying\". Oh my God, you\\'d think she was being forced to date Ben Affleck or something horrible like that. Um, wait...<br /><br />THE BAD GUYS/GAL: They show about the same range of expression and acting ability that you\\'d expect from a slightly overripe grapefruit. At least next to JGar\\'s performance, it doesn\\'t stand out too badly. One guy\\'s role is to stand there and be huge, another\\'s is to stand there and have stuff come out of him, and the woman\\'s role is to stand there and breathe on and/or kiss people. They manage to pull these incredible feats off. The main bad guy has the most difficult role of all - he has to SIMULTANEOUSLY a) appear angry and b) appear Asian. He does a fine job at this. I think there was a fifth bad guy/gal, but my brain is starting to block parts of this movie out in self-defense.<br /><br />PLOT TWISTS! This movie has about as many surprises as a speech at the Democratic National Convention. Let\\'s just put it this way - my wife, who has only been in the U.S. for half a year and speaks only a small amount of English - whispered this to me when the girl first appears in JG\\'s pad, and I swear to God I am not making this up: \"She go to house to kill girl. And father too.\" And this is BEFORE THE FATHER HAS EVEN APPEARED ON THE SCREEN. Now my wife isn\\'t stupid, but she isn\\'t being courted by Mensa for her gifts, either, and she\\'s had zero exposure to Daredevil or the comic book genre. And she figured this out in .00015 seconds with no prodding and no prior information. Such is the blatant obviousness of this film. <br /><br />RARELY-BEFORE-SEEN STUPIDITY! OK, so there\\'s this big dude in the film. He can take a chestful of shotgun blast and brush off the shot like it\\'s lint, and he can take a vicious Electra stab to the chest and just bend the metal (or melt it - or something - more defenses kicking in, thank God). But JG jumps on his head, and he explodes? An Achilles noggin? OK! Such is the mind-numbing stupidity of this film.<br /><br />Ack. I\\'m starting to feel a cerebral hemorrhage coming on, so I have to stop. But you have been warned. If you have to intentionally slash your own tires to prevent yourself from going to see this movie, DO IT. And if Armageddon is going to come, please let it be >before< this comes out on DVD.'\n",
            "1 b'I\\'ve read some terrible things about this film, so I was prepared for the worst. \"Confusing. Muddled. Horribly structured.\" While there may be merit to some of these accusations, this film was nowhere near as horrific as your average DVD programmer. In fact, it actually had aspirations. It attempted something beyond the typical monster/slasher nonsense. And by god, there are some interesting things going on.<br /><br />Ms. Barbeau is a miracle to behold. She carries the film squarely on her shoulders.<br /><br />This is not to say that it\\'s a masterpiece. UNHOLY ultimately collapses under the weight of its own ambition. There are just too many (unexplained) subplots trying to coexist. And the plot loopholes created by time travel are never really addressed: for example, if Hope knows that her mother is evil and that she will ultimately kill her brother, then why doesn\\'t she just kill Ma in the film\\'s very first sequence? Seems like it would have beat the hell out of traveling into the future to do it.<br /><br />Still, I give UNHOLY points for trying. A little ambition is not a bad thing.'\n",
            "1 b'Nina Foch delivers a surprisingly strong performance as the title character in this fun little Gothic nail-biter. She accepts a position as secretary to a London society dowager (played imperiously by Dame May Witty) and her creepy son (the effete and bothersome George Macready). Before she knows it, she awakens to find herself in a seaside manor she\\'s never seen before, where Witty and Macready are calling her Marian and trying to convince the servants and the nearby townspeople that she\\'s Macready\\'s mad wife. Of course this pair can only be planning dastardly deeds, and even though we know Julia has to eventually escape her trap, director Joseph Lewis builds real suspense in answering the question of just how she\\'ll manage it.<br /><br />\"My Name Is Julia Ross\" has nothing stylistically to set it apart from any number of films that came out at the same time period, but I was surprised by how well it held together despite its shoe-string budget and B-movie pedigree. There are quite a few moments that just may have you on the edge of your seat, and I found myself really rooting for Julia as she caught on to the scheme underfoot and began to outsmart her captors. In any other Gothic thriller, the heroine would have swooned, screamed and dithered, waiting for her hero to come and save her. So I can\\'t tell you how refreshing it was to have the heroine in this film use her brain and figure out how to save herself.<br /><br />Well done.<br /><br />Grade: B+'\n",
            "1 b'Here\\'s the kind of love story that I do enjoy watching. And mostly, it\\'s for two reasons. One, it concentrates of young people, VERY young people. People who are still in their teens and are experiencing love for the first time, or at least think they are. All of us have been there in our lives and \"The Man in the Moon\" is a magnificent reflection upon our memories, maybe adding on a few more details and enhancing it further than any of us have experienced. The second reason is that is a love triangle. And I do believe that as teens, it\\'s the most dramatic. And the story is so well developed that you believe the characters could really be in love, or are just so new to love that they just strongly believe they are and after a tragedy or so occurs, will believe it for the rest of their lives.<br /><br />The cast of \"The Man in the Moon\" is full of great talented names. It stars Sam Waterston, who is truly a versatile actor, well capable of playing tough district attorneys as well as strict, yet caring and wise fathers as in this film. Also there is Tess Harper, Jason London, and a young, young Reese Witherspoon. You look at the young, talented actress as she is at age fourteen and you think that about ten years down the road, she\\'s going to win the Academy Award. All members of the cast pull off great performances and with the dialogue of the compelling screenplay, they are enhanced into looking like real people in real situations. As if it all really happened. This the kind of movie that I would like to see come out more often. Love story or not. I would love to see films that make everything look real and is not phony or disbelievable in any way.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "fVFSVjo5mLDc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed a 1,000 word vocabulary into 5 dimensions.\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=1000, output_dim=5)"
      ],
      "metadata": {
        "id": "OKmjhBDCmnYo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = embedding_layer(tf.constant([1, 2, 3]))\n",
        "result.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVtpNLrQm2ux",
        "outputId": "2c587c17-60ed-45af-a522-016e47e9091b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.02095643, -0.0419461 , -0.03078711,  0.04141687, -0.0284851 ],\n",
              "       [-0.00714672, -0.03461951,  0.01894302, -0.04981021, -0.02386205],\n",
              "       [-0.02369664,  0.02954148, -0.01014899,  0.03782015,  0.00205079]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = embedding_layer(tf.constant([[0, 1, 2], [3, 4, 5]]))\n",
        "result.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zETV490pm-D3",
        "outputId": "ef603708-9a0f-419a-bca5-2d342673f8b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a custom standardization function to strip HTML break tags '<br />'\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html, \n",
        "                                  '[%s]' % re.escape(string.punctuation), '')\n",
        "  \n",
        "# Vocabulary size and number of words in a sequence\n",
        "vocab_size = 10000\n",
        "sequence_length = 100\n",
        "\n",
        "# Use the text vectorization layer to normalize, split, and map strings to \n",
        "# integers. Note that the layer uses the custom standardization defined above.\n",
        "# Set maximum_sequence length as all samples are not of the same length.\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "# Make a text only dataset (no labels) and call adapt to build the vocabulary\n",
        "text_ds = train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E223JtrXnKUe",
        "outputId": "c511e493-833b-4e39-a106-14f3f3bd0ff8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 16\n",
        "\n",
        "model = Sequential([\n",
        "    vectorize_layer, \n",
        "    Embedding(vocab_size, embedding_dim, name='embedding'),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(19, activation='relu'),\n",
        "    Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "U-We1edZpn1u"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs')"
      ],
      "metadata": {
        "id": "TkQtoJ2NqiK5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "eO8bUaznquaz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=15,\n",
        "          callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq-lSovsq60J",
        "outputId": "db705ae5-e448-492b-da06-f56ad51a22f3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "20/20 [==============================] - 10s 257ms/step - loss: 1.4938 - accuracy: 0.5028 - val_loss: 1.1047 - val_accuracy: 0.4886\n",
            "Epoch 2/15\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.9698 - accuracy: 0.5028 - val_loss: 0.8906 - val_accuracy: 0.4886\n",
            "Epoch 3/15\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.8210 - accuracy: 0.5028 - val_loss: 0.7824 - val_accuracy: 0.4886\n",
            "Epoch 4/15\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.7401 - accuracy: 0.5038 - val_loss: 0.7201 - val_accuracy: 0.4920\n",
            "Epoch 5/15\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.6947 - accuracy: 0.5134 - val_loss: 0.6865 - val_accuracy: 0.5068\n",
            "Epoch 6/15\n",
            "20/20 [==============================] - 1s 58ms/step - loss: 0.6704 - accuracy: 0.5340 - val_loss: 0.6686 - val_accuracy: 0.5608\n",
            "Epoch 7/15\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.6548 - accuracy: 0.6873 - val_loss: 0.6558 - val_accuracy: 0.7216\n",
            "Epoch 8/15\n",
            "20/20 [==============================] - 1s 60ms/step - loss: 0.6406 - accuracy: 0.7894 - val_loss: 0.6434 - val_accuracy: 0.7610\n",
            "Epoch 9/15\n",
            "20/20 [==============================] - 2s 126ms/step - loss: 0.6254 - accuracy: 0.8083 - val_loss: 0.6301 - val_accuracy: 0.7710\n",
            "Epoch 10/15\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.6087 - accuracy: 0.8151 - val_loss: 0.6154 - val_accuracy: 0.7790\n",
            "Epoch 11/15\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.5898 - accuracy: 0.8184 - val_loss: 0.5989 - val_accuracy: 0.7842\n",
            "Epoch 12/15\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.5683 - accuracy: 0.8242 - val_loss: 0.5803 - val_accuracy: 0.7872\n",
            "Epoch 13/15\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.5438 - accuracy: 0.8303 - val_loss: 0.5593 - val_accuracy: 0.7916\n",
            "Epoch 14/15\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.5162 - accuracy: 0.8353 - val_loss: 0.5363 - val_accuracy: 0.7956\n",
            "Epoch 15/15\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.4859 - accuracy: 0.8400 - val_loss: 0.5119 - val_accuracy: 0.7980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd781c416a0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rOEZe5lrEsP",
        "outputId": "961fad15-f004-4fb8-d3cc-6cbc6c7d5617"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 100)              0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 100, 16)           160000    \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 16)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 19)                323       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,343\n",
            "Trainable params: 160,343\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev upload --logdir ./logs \\\n",
        "  --name \"tf_word_embeddings\" \\\n",
        "  --description \"tf word embeddings documentation\" \\\n",
        "  --one_shot"
      ],
      "metadata": {
        "id": "AHeOZpXDtXsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Done. View your TensorBoard at https://tensorboard.dev/experiment/563vImm5TDCMF80zi84XFg/"
      ],
      "metadata": {
        "id": "aPzo4_K2t0bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard list"
      ],
      "metadata": {
        "id": "S-iEsvEetqna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # docs_infra: no_execute\n",
        "# %load_ext tensorboard \n",
        "# %tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "8JyD6WSpsoWz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_layer('embedding').get_weights()[0]\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "id": "ooBmWn8Fs2W8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "  if index == 0:\n",
        "    continue # skip 0, it's padding\n",
        "  vec = weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + '\\n')\n",
        "  out_m.write(word + '\\n')\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "HSn9uXl6uVwu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "a-JJfsZrvM1c",
        "outputId": "3f416f69-2485-4c04-b9f0-119363a5cf80"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_770f41ce-8839-465e-849b-c90e8c88633b\", \"vecs.tsv\", 1937319)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fe3cef1a-e274-48cd-983c-c7c693733153\", \"meta.tsv\", 76492)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LM-EER12vd58"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}